{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EXt_x_lbK2K"
      },
      "source": [
        "!rm -rf TheSchoolOfAI-EVA5-Assignments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn_5RFQrHxBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6183205-d491-4857-edc5-556bb7e6d2de"
      },
      "source": [
        "!git clone \"https://github.com/divyam96/TheSchoolOfAI-EVA5-Assignments.git\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TheSchoolOfAI-EVA5-Assignments'...\n",
            "remote: Enumerating objects: 507, done.\u001b[K\n",
            "remote: Counting objects: 100% (507/507), done.\u001b[K\n",
            "remote: Compressing objects: 100% (455/455), done.\u001b[K\n",
            "remote: Total 1000 (delta 115), reused 331 (delta 20), pack-reused 493\u001b[K\n",
            "Receiving objects: 100% (1000/1000), 43.19 MiB | 19.32 MiB/s, done.\n",
            "Resolving deltas: 100% (314/314), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl7DDzcpJ8Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fc8af9-f429-425e-ef6f-dec75bbdc35d"
      },
      "source": [
        "%cd \"TheSchoolOfAI-EVA5-Assignments/Assignment 15/divyam\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TheSchoolOfAI-EVA5-Assignments/Assignment 15/divyam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2-SHZsOVr91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe561d9e-8a5a-4289-dde7-72ace9e1a130"
      },
      "source": [
        "!wget \"https://github.com/intel-isl/MiDaS/releases/download/v2/model-f46da743.pt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-22 06:50:32--  https://github.com/intel-isl/MiDaS/releases/download/v2/model-f46da743.pt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/193518067/cb0db580-a735-11ea-905c-4083069b9be1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201122T065032Z&X-Amz-Expires=300&X-Amz-Signature=d2aeb769a1c5cad3d504617c7ce0d64f2947dd67bd7967c49b4569a5f1e2a2fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193518067&response-content-disposition=attachment%3B%20filename%3Dmodel-f46da743.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-11-22 06:50:32--  https://github-production-release-asset-2e65be.s3.amazonaws.com/193518067/cb0db580-a735-11ea-905c-4083069b9be1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201122T065032Z&X-Amz-Expires=300&X-Amz-Signature=d2aeb769a1c5cad3d504617c7ce0d64f2947dd67bd7967c49b4569a5f1e2a2fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193518067&response-content-disposition=attachment%3B%20filename%3Dmodel-f46da743.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.16.180\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.16.180|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 422388453 (403M) [application/octet-stream]\n",
            "Saving to: ‘model-f46da743.pt’\n",
            "\n",
            "model-f46da743.pt   100%[===================>] 402.82M  34.9MB/s    in 12s     \n",
            "\n",
            "2020-11-22 06:50:44 (33.1 MB/s) - ‘model-f46da743.pt’ saved [422388453/422388453]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmwJYZ9fwodJ"
      },
      "source": [
        "!cp \"/content/drive/My Drive/TheSchoolOfAI/YoloV3_Dataset.zip\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVxQoIobxKxi"
      },
      "source": [
        "!unzip -q YoloV3_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VZ-fMUOzrss"
      },
      "source": [
        "from utils import parse_data_cfg\n",
        "data = parse_data_cfg(\"custom.data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-csojc7f0lCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45f5684-46d4-4154-af63-850ad00375f1"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes': '4',\n",
              " 'names': 'classes.txt',\n",
              " 'train': 'train.txt',\n",
              " 'valid': 'test.txt'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3Owhpt0lGY"
      },
      "source": [
        "from datasets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVTYWvQq3LTF"
      },
      "source": [
        "hyp = {'giou': 3.54,  # giou loss gain\n",
        "       'cls': 37.4,  # cls loss gain\n",
        "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
        "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
        "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
        "       'iou_t': 0.225,  # iou training threshold\n",
        "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
        "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
        "       'momentum': 0.937,  # SGD momentum\n",
        "       'weight_decay': 0.000484,  # optimizer weight decay\n",
        "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
        "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
        "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
        "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
        "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
        "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
        "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
        "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
        "\n",
        "yolo_cfg = {'type': 'yolo', 'mask': [[0, 1, 2],[3, 4, 5], [6, 7, 8]],\n",
        "                    'anchors': np.array([[ 10.,  13.],\n",
        "       [ 16.,  30.],\n",
        "       [ 33.,  23.],\n",
        "       [ 30.,  61.],\n",
        "       [ 62.,  45.],\n",
        "       [ 59., 119.],\n",
        "       [116.,  90.],\n",
        "       [156., 198.],\n",
        "       [373., 326.]]), 'classes': 4, 'num': 9, 'jitter': '.3', 'ignore_thresh': '.7',\n",
        "                    'truth_thresh': 1, 'random': 1, 'stride': [32, 16, 8]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oODMdVp2z53Z"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class ModelEMA:\n",
        "    \"\"\" Model Exponential Moving Average from https://github.com/rwightman/pytorch-image-models\n",
        "    Keep a moving average of everything in the model state_dict (parameters and buffers).\n",
        "    This is intended to allow functionality like\n",
        "    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
        "    A smoothed version of the weights is necessary for some training schemes to perform well.\n",
        "    E.g. Google's hyper-params for training MNASNet, MobileNet-V3, EfficientNet, etc that use\n",
        "    RMSprop with a short 2.4-3 epoch decay period and slow LR decay rate of .96-.99 requires EMA\n",
        "    smoothing of weights to match results. Pay attention to the decay constant you are using\n",
        "    relative to your update count per epoch.\n",
        "    To keep EMA from using GPU resources, set device='cpu'. This will save a bit of memory but\n",
        "    disable validation of the EMA weights. Validation will have to be done manually in a separate\n",
        "    process, or after the training stops converging.\n",
        "    This class is sensitive where it is initialized in the sequence of model init,\n",
        "    GPU assignment and distributed training wrappers.\n",
        "    I've tested with the sequence in my own train.py for torch.DataParallel, apex.DDP, and single-GPU.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, decay=0.9999, device=''):\n",
        "        # make a copy of the model for accumulating moving average of weights\n",
        "        self.ema = deepcopy(model)\n",
        "        self.ema.eval()\n",
        "        self.updates = 0  # number of EMA updates\n",
        "        self.decay = lambda x: decay * (1 - math.exp(-x / 2000))  # decay exponential ramp (to help early epochs)\n",
        "        self.device = device  # perform ema on different device from model if set\n",
        "        if device:\n",
        "            self.ema.to(device=device)\n",
        "        for p in self.ema.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "    def update(self, model):\n",
        "        self.updates += 1\n",
        "        d = self.decay(self.updates)\n",
        "        with torch.no_grad():\n",
        "            if type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel):\n",
        "                msd, esd = model.module.state_dict(), self.ema.module.state_dict()\n",
        "            else:\n",
        "                msd, esd = model.state_dict(), self.ema.state_dict()\n",
        "\n",
        "            for k, v in esd.items():\n",
        "                if v.dtype.is_floating_point:\n",
        "                    v *= d\n",
        "                    v += (1. - d) * msd[k].detach()\n",
        "\n",
        "    def update_attr(self, model):\n",
        "        # Assign attributes (which may change during training)\n",
        "        for k in model.__dict__.keys():\n",
        "            if not k.startswith('_'):\n",
        "                setattr(self.ema, k, getattr(model, k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7lV4Sxvl98l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5dd64d-2905-4f06-b9ee-632d444d4dd2"
      },
      "source": [
        "batch_size=1\n",
        "img_size=512\n",
        "dataset = LoadImagesAndLabels(data['train'], img_size, batch_size,\n",
        "                                  augment=True,\n",
        "                                  hyp=hyp,  # augmentation hyperparameters\n",
        "                                  rect=False,  # rectangular training\n",
        "                                  cache_images=False,\n",
        "                                  single_cls=False)\n",
        "dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          num_workers=4,\n",
        "                                          shuffle=True,  # Shuffle=True unless rectangular training is used\n",
        "                                          pin_memory=True,\n",
        "                                          collate_fn=dataset.collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caching labels (2860 found, 131 missing, 38 empty, 0 duplicate, for 3029 images): 100%|██████████| 3029/3029 [00:00<00:00, 7609.68it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VixWSMPH9A5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5287b33-adf4-4f4e-816d-05965a60ca82"
      },
      "source": [
        "test_batch_size=1\n",
        "testloader = torch.utils.data.DataLoader(LoadImagesAndLabels(data['valid'], img_size, test_batch_size,\n",
        "                                                                 hyp=hyp,\n",
        "                                                                #  rect=True,\n",
        "                                                                 cache_images=True,\n",
        "                                                                 single_cls=False),\n",
        "                                             batch_size=test_batch_size,\n",
        "                                             num_workers=4,\n",
        "                                             pin_memory=True,\n",
        "                                             collate_fn=dataset.collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caching labels (296 found, 14 missing, 7 empty, 0 duplicate, for 317 images): 100%|██████████| 317/317 [00:00<00:00, 6704.36it/s]\n",
            "Caching images (0.1GB): 100%|██████████| 317/317 [00:03<00:00, 102.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAG89W7r_qDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b183d12-0dba-4bdf-cff2-d15d26790feb"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn as nn\n",
        "\n",
        "from model import CustomNet\n",
        "from utils import compute_loss\n",
        "# from test import test\n",
        "\n",
        "batch_size = min(batch_size, len(dataset))\n",
        "# accumulate=4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device: %s\" % device)\n",
        "\n",
        "model = CustomNet(\"model-f46da743.pt\", non_negative=True, yolo_cfg=yolo_cfg)\n",
        "model.gr = 1.0\n",
        "model.hyp = hyp\n",
        "model.to(device)\n",
        "ema = ModelEMA(model)\n",
        "dict(model.named_parameters()).keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "Loading weights:  model-f46da743.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['pretrained.layer1.0.weight', 'pretrained.layer1.1.weight', 'pretrained.layer1.1.bias', 'pretrained.layer1.4.0.conv1.weight', 'pretrained.layer1.4.0.bn1.weight', 'pretrained.layer1.4.0.bn1.bias', 'pretrained.layer1.4.0.conv2.weight', 'pretrained.layer1.4.0.bn2.weight', 'pretrained.layer1.4.0.bn2.bias', 'pretrained.layer1.4.0.conv3.weight', 'pretrained.layer1.4.0.bn3.weight', 'pretrained.layer1.4.0.bn3.bias', 'pretrained.layer1.4.0.downsample.0.weight', 'pretrained.layer1.4.0.downsample.1.weight', 'pretrained.layer1.4.0.downsample.1.bias', 'pretrained.layer1.4.1.conv1.weight', 'pretrained.layer1.4.1.bn1.weight', 'pretrained.layer1.4.1.bn1.bias', 'pretrained.layer1.4.1.conv2.weight', 'pretrained.layer1.4.1.bn2.weight', 'pretrained.layer1.4.1.bn2.bias', 'pretrained.layer1.4.1.conv3.weight', 'pretrained.layer1.4.1.bn3.weight', 'pretrained.layer1.4.1.bn3.bias', 'pretrained.layer1.4.2.conv1.weight', 'pretrained.layer1.4.2.bn1.weight', 'pretrained.layer1.4.2.bn1.bias', 'pretrained.layer1.4.2.conv2.weight', 'pretrained.layer1.4.2.bn2.weight', 'pretrained.layer1.4.2.bn2.bias', 'pretrained.layer1.4.2.conv3.weight', 'pretrained.layer1.4.2.bn3.weight', 'pretrained.layer1.4.2.bn3.bias', 'pretrained.layer2.0.conv1.weight', 'pretrained.layer2.0.bn1.weight', 'pretrained.layer2.0.bn1.bias', 'pretrained.layer2.0.conv2.weight', 'pretrained.layer2.0.bn2.weight', 'pretrained.layer2.0.bn2.bias', 'pretrained.layer2.0.conv3.weight', 'pretrained.layer2.0.bn3.weight', 'pretrained.layer2.0.bn3.bias', 'pretrained.layer2.0.downsample.0.weight', 'pretrained.layer2.0.downsample.1.weight', 'pretrained.layer2.0.downsample.1.bias', 'pretrained.layer2.1.conv1.weight', 'pretrained.layer2.1.bn1.weight', 'pretrained.layer2.1.bn1.bias', 'pretrained.layer2.1.conv2.weight', 'pretrained.layer2.1.bn2.weight', 'pretrained.layer2.1.bn2.bias', 'pretrained.layer2.1.conv3.weight', 'pretrained.layer2.1.bn3.weight', 'pretrained.layer2.1.bn3.bias', 'pretrained.layer2.2.conv1.weight', 'pretrained.layer2.2.bn1.weight', 'pretrained.layer2.2.bn1.bias', 'pretrained.layer2.2.conv2.weight', 'pretrained.layer2.2.bn2.weight', 'pretrained.layer2.2.bn2.bias', 'pretrained.layer2.2.conv3.weight', 'pretrained.layer2.2.bn3.weight', 'pretrained.layer2.2.bn3.bias', 'pretrained.layer2.3.conv1.weight', 'pretrained.layer2.3.bn1.weight', 'pretrained.layer2.3.bn1.bias', 'pretrained.layer2.3.conv2.weight', 'pretrained.layer2.3.bn2.weight', 'pretrained.layer2.3.bn2.bias', 'pretrained.layer2.3.conv3.weight', 'pretrained.layer2.3.bn3.weight', 'pretrained.layer2.3.bn3.bias', 'pretrained.layer3.0.conv1.weight', 'pretrained.layer3.0.bn1.weight', 'pretrained.layer3.0.bn1.bias', 'pretrained.layer3.0.conv2.weight', 'pretrained.layer3.0.bn2.weight', 'pretrained.layer3.0.bn2.bias', 'pretrained.layer3.0.conv3.weight', 'pretrained.layer3.0.bn3.weight', 'pretrained.layer3.0.bn3.bias', 'pretrained.layer3.0.downsample.0.weight', 'pretrained.layer3.0.downsample.1.weight', 'pretrained.layer3.0.downsample.1.bias', 'pretrained.layer3.1.conv1.weight', 'pretrained.layer3.1.bn1.weight', 'pretrained.layer3.1.bn1.bias', 'pretrained.layer3.1.conv2.weight', 'pretrained.layer3.1.bn2.weight', 'pretrained.layer3.1.bn2.bias', 'pretrained.layer3.1.conv3.weight', 'pretrained.layer3.1.bn3.weight', 'pretrained.layer3.1.bn3.bias', 'pretrained.layer3.2.conv1.weight', 'pretrained.layer3.2.bn1.weight', 'pretrained.layer3.2.bn1.bias', 'pretrained.layer3.2.conv2.weight', 'pretrained.layer3.2.bn2.weight', 'pretrained.layer3.2.bn2.bias', 'pretrained.layer3.2.conv3.weight', 'pretrained.layer3.2.bn3.weight', 'pretrained.layer3.2.bn3.bias', 'pretrained.layer3.3.conv1.weight', 'pretrained.layer3.3.bn1.weight', 'pretrained.layer3.3.bn1.bias', 'pretrained.layer3.3.conv2.weight', 'pretrained.layer3.3.bn2.weight', 'pretrained.layer3.3.bn2.bias', 'pretrained.layer3.3.conv3.weight', 'pretrained.layer3.3.bn3.weight', 'pretrained.layer3.3.bn3.bias', 'pretrained.layer3.4.conv1.weight', 'pretrained.layer3.4.bn1.weight', 'pretrained.layer3.4.bn1.bias', 'pretrained.layer3.4.conv2.weight', 'pretrained.layer3.4.bn2.weight', 'pretrained.layer3.4.bn2.bias', 'pretrained.layer3.4.conv3.weight', 'pretrained.layer3.4.bn3.weight', 'pretrained.layer3.4.bn3.bias', 'pretrained.layer3.5.conv1.weight', 'pretrained.layer3.5.bn1.weight', 'pretrained.layer3.5.bn1.bias', 'pretrained.layer3.5.conv2.weight', 'pretrained.layer3.5.bn2.weight', 'pretrained.layer3.5.bn2.bias', 'pretrained.layer3.5.conv3.weight', 'pretrained.layer3.5.bn3.weight', 'pretrained.layer3.5.bn3.bias', 'pretrained.layer3.6.conv1.weight', 'pretrained.layer3.6.bn1.weight', 'pretrained.layer3.6.bn1.bias', 'pretrained.layer3.6.conv2.weight', 'pretrained.layer3.6.bn2.weight', 'pretrained.layer3.6.bn2.bias', 'pretrained.layer3.6.conv3.weight', 'pretrained.layer3.6.bn3.weight', 'pretrained.layer3.6.bn3.bias', 'pretrained.layer3.7.conv1.weight', 'pretrained.layer3.7.bn1.weight', 'pretrained.layer3.7.bn1.bias', 'pretrained.layer3.7.conv2.weight', 'pretrained.layer3.7.bn2.weight', 'pretrained.layer3.7.bn2.bias', 'pretrained.layer3.7.conv3.weight', 'pretrained.layer3.7.bn3.weight', 'pretrained.layer3.7.bn3.bias', 'pretrained.layer3.8.conv1.weight', 'pretrained.layer3.8.bn1.weight', 'pretrained.layer3.8.bn1.bias', 'pretrained.layer3.8.conv2.weight', 'pretrained.layer3.8.bn2.weight', 'pretrained.layer3.8.bn2.bias', 'pretrained.layer3.8.conv3.weight', 'pretrained.layer3.8.bn3.weight', 'pretrained.layer3.8.bn3.bias', 'pretrained.layer3.9.conv1.weight', 'pretrained.layer3.9.bn1.weight', 'pretrained.layer3.9.bn1.bias', 'pretrained.layer3.9.conv2.weight', 'pretrained.layer3.9.bn2.weight', 'pretrained.layer3.9.bn2.bias', 'pretrained.layer3.9.conv3.weight', 'pretrained.layer3.9.bn3.weight', 'pretrained.layer3.9.bn3.bias', 'pretrained.layer3.10.conv1.weight', 'pretrained.layer3.10.bn1.weight', 'pretrained.layer3.10.bn1.bias', 'pretrained.layer3.10.conv2.weight', 'pretrained.layer3.10.bn2.weight', 'pretrained.layer3.10.bn2.bias', 'pretrained.layer3.10.conv3.weight', 'pretrained.layer3.10.bn3.weight', 'pretrained.layer3.10.bn3.bias', 'pretrained.layer3.11.conv1.weight', 'pretrained.layer3.11.bn1.weight', 'pretrained.layer3.11.bn1.bias', 'pretrained.layer3.11.conv2.weight', 'pretrained.layer3.11.bn2.weight', 'pretrained.layer3.11.bn2.bias', 'pretrained.layer3.11.conv3.weight', 'pretrained.layer3.11.bn3.weight', 'pretrained.layer3.11.bn3.bias', 'pretrained.layer3.12.conv1.weight', 'pretrained.layer3.12.bn1.weight', 'pretrained.layer3.12.bn1.bias', 'pretrained.layer3.12.conv2.weight', 'pretrained.layer3.12.bn2.weight', 'pretrained.layer3.12.bn2.bias', 'pretrained.layer3.12.conv3.weight', 'pretrained.layer3.12.bn3.weight', 'pretrained.layer3.12.bn3.bias', 'pretrained.layer3.13.conv1.weight', 'pretrained.layer3.13.bn1.weight', 'pretrained.layer3.13.bn1.bias', 'pretrained.layer3.13.conv2.weight', 'pretrained.layer3.13.bn2.weight', 'pretrained.layer3.13.bn2.bias', 'pretrained.layer3.13.conv3.weight', 'pretrained.layer3.13.bn3.weight', 'pretrained.layer3.13.bn3.bias', 'pretrained.layer3.14.conv1.weight', 'pretrained.layer3.14.bn1.weight', 'pretrained.layer3.14.bn1.bias', 'pretrained.layer3.14.conv2.weight', 'pretrained.layer3.14.bn2.weight', 'pretrained.layer3.14.bn2.bias', 'pretrained.layer3.14.conv3.weight', 'pretrained.layer3.14.bn3.weight', 'pretrained.layer3.14.bn3.bias', 'pretrained.layer3.15.conv1.weight', 'pretrained.layer3.15.bn1.weight', 'pretrained.layer3.15.bn1.bias', 'pretrained.layer3.15.conv2.weight', 'pretrained.layer3.15.bn2.weight', 'pretrained.layer3.15.bn2.bias', 'pretrained.layer3.15.conv3.weight', 'pretrained.layer3.15.bn3.weight', 'pretrained.layer3.15.bn3.bias', 'pretrained.layer3.16.conv1.weight', 'pretrained.layer3.16.bn1.weight', 'pretrained.layer3.16.bn1.bias', 'pretrained.layer3.16.conv2.weight', 'pretrained.layer3.16.bn2.weight', 'pretrained.layer3.16.bn2.bias', 'pretrained.layer3.16.conv3.weight', 'pretrained.layer3.16.bn3.weight', 'pretrained.layer3.16.bn3.bias', 'pretrained.layer3.17.conv1.weight', 'pretrained.layer3.17.bn1.weight', 'pretrained.layer3.17.bn1.bias', 'pretrained.layer3.17.conv2.weight', 'pretrained.layer3.17.bn2.weight', 'pretrained.layer3.17.bn2.bias', 'pretrained.layer3.17.conv3.weight', 'pretrained.layer3.17.bn3.weight', 'pretrained.layer3.17.bn3.bias', 'pretrained.layer3.18.conv1.weight', 'pretrained.layer3.18.bn1.weight', 'pretrained.layer3.18.bn1.bias', 'pretrained.layer3.18.conv2.weight', 'pretrained.layer3.18.bn2.weight', 'pretrained.layer3.18.bn2.bias', 'pretrained.layer3.18.conv3.weight', 'pretrained.layer3.18.bn3.weight', 'pretrained.layer3.18.bn3.bias', 'pretrained.layer3.19.conv1.weight', 'pretrained.layer3.19.bn1.weight', 'pretrained.layer3.19.bn1.bias', 'pretrained.layer3.19.conv2.weight', 'pretrained.layer3.19.bn2.weight', 'pretrained.layer3.19.bn2.bias', 'pretrained.layer3.19.conv3.weight', 'pretrained.layer3.19.bn3.weight', 'pretrained.layer3.19.bn3.bias', 'pretrained.layer3.20.conv1.weight', 'pretrained.layer3.20.bn1.weight', 'pretrained.layer3.20.bn1.bias', 'pretrained.layer3.20.conv2.weight', 'pretrained.layer3.20.bn2.weight', 'pretrained.layer3.20.bn2.bias', 'pretrained.layer3.20.conv3.weight', 'pretrained.layer3.20.bn3.weight', 'pretrained.layer3.20.bn3.bias', 'pretrained.layer3.21.conv1.weight', 'pretrained.layer3.21.bn1.weight', 'pretrained.layer3.21.bn1.bias', 'pretrained.layer3.21.conv2.weight', 'pretrained.layer3.21.bn2.weight', 'pretrained.layer3.21.bn2.bias', 'pretrained.layer3.21.conv3.weight', 'pretrained.layer3.21.bn3.weight', 'pretrained.layer3.21.bn3.bias', 'pretrained.layer3.22.conv1.weight', 'pretrained.layer3.22.bn1.weight', 'pretrained.layer3.22.bn1.bias', 'pretrained.layer3.22.conv2.weight', 'pretrained.layer3.22.bn2.weight', 'pretrained.layer3.22.bn2.bias', 'pretrained.layer3.22.conv3.weight', 'pretrained.layer3.22.bn3.weight', 'pretrained.layer3.22.bn3.bias', 'pretrained.layer4.0.conv1.weight', 'pretrained.layer4.0.bn1.weight', 'pretrained.layer4.0.bn1.bias', 'pretrained.layer4.0.conv2.weight', 'pretrained.layer4.0.bn2.weight', 'pretrained.layer4.0.bn2.bias', 'pretrained.layer4.0.conv3.weight', 'pretrained.layer4.0.bn3.weight', 'pretrained.layer4.0.bn3.bias', 'pretrained.layer4.0.downsample.0.weight', 'pretrained.layer4.0.downsample.1.weight', 'pretrained.layer4.0.downsample.1.bias', 'pretrained.layer4.1.conv1.weight', 'pretrained.layer4.1.bn1.weight', 'pretrained.layer4.1.bn1.bias', 'pretrained.layer4.1.conv2.weight', 'pretrained.layer4.1.bn2.weight', 'pretrained.layer4.1.bn2.bias', 'pretrained.layer4.1.conv3.weight', 'pretrained.layer4.1.bn3.weight', 'pretrained.layer4.1.bn3.bias', 'pretrained.layer4.2.conv1.weight', 'pretrained.layer4.2.bn1.weight', 'pretrained.layer4.2.bn1.bias', 'pretrained.layer4.2.conv2.weight', 'pretrained.layer4.2.bn2.weight', 'pretrained.layer4.2.bn2.bias', 'pretrained.layer4.2.conv3.weight', 'pretrained.layer4.2.bn3.weight', 'pretrained.layer4.2.bn3.bias', 'scratch.layer1_rn.weight', 'scratch.layer2_rn.weight', 'scratch.layer3_rn.weight', 'scratch.layer4_rn.weight', 'scratch.refinenet4.resConfUnit1.conv1.weight', 'scratch.refinenet4.resConfUnit1.conv1.bias', 'scratch.refinenet4.resConfUnit1.conv2.weight', 'scratch.refinenet4.resConfUnit1.conv2.bias', 'scratch.refinenet4.resConfUnit2.conv1.weight', 'scratch.refinenet4.resConfUnit2.conv1.bias', 'scratch.refinenet4.resConfUnit2.conv2.weight', 'scratch.refinenet4.resConfUnit2.conv2.bias', 'scratch.refinenet3.resConfUnit1.conv1.weight', 'scratch.refinenet3.resConfUnit1.conv1.bias', 'scratch.refinenet3.resConfUnit1.conv2.weight', 'scratch.refinenet3.resConfUnit1.conv2.bias', 'scratch.refinenet3.resConfUnit2.conv1.weight', 'scratch.refinenet3.resConfUnit2.conv1.bias', 'scratch.refinenet3.resConfUnit2.conv2.weight', 'scratch.refinenet3.resConfUnit2.conv2.bias', 'scratch.refinenet2.resConfUnit1.conv1.weight', 'scratch.refinenet2.resConfUnit1.conv1.bias', 'scratch.refinenet2.resConfUnit1.conv2.weight', 'scratch.refinenet2.resConfUnit1.conv2.bias', 'scratch.refinenet2.resConfUnit2.conv1.weight', 'scratch.refinenet2.resConfUnit2.conv1.bias', 'scratch.refinenet2.resConfUnit2.conv2.weight', 'scratch.refinenet2.resConfUnit2.conv2.bias', 'scratch.refinenet1.resConfUnit1.conv1.weight', 'scratch.refinenet1.resConfUnit1.conv1.bias', 'scratch.refinenet1.resConfUnit1.conv2.weight', 'scratch.refinenet1.resConfUnit1.conv2.bias', 'scratch.refinenet1.resConfUnit2.conv1.weight', 'scratch.refinenet1.resConfUnit2.conv1.bias', 'scratch.refinenet1.resConfUnit2.conv2.weight', 'scratch.refinenet1.resConfUnit2.conv2.bias', 'scratch.output_conv.0.weight', 'scratch.output_conv.0.bias', 'scratch.output_conv.2.weight', 'scratch.output_conv.2.bias', 'scratch.output_conv.4.weight', 'scratch.output_conv.4.bias', 'yolo_init.weight', 'yolo_init.bias', 'yolo_init2.weight', 'yolo_init2.bias', 'yolo_preconv1.conv1.weight', 'yolo_preconv1.conv1.bias', 'yolo_preconv1.conv2.weight', 'yolo_preconv1.conv2.bias', 'yolo_preconv1.bn.weight', 'yolo_preconv1.bn.bias', 'yolo_preconv2.conv1.weight', 'yolo_preconv2.conv1.bias', 'yolo_preconv2.conv2.weight', 'yolo_preconv2.conv2.bias', 'yolo_preconv2.bn.weight', 'yolo_preconv2.bn.bias', 'yolo_postconv.weight', 'yolo_postconv.bias', 'yolo_mid_block.0.weight', 'yolo_mid_block.0.bias', 'yolo_mid_block.1.weight', 'yolo_mid_block.1.bias', 'yolo_mid_block.2.conv1.weight', 'yolo_mid_block.2.conv1.bias', 'yolo_mid_block.2.conv2.weight', 'yolo_mid_block.2.conv2.bias', 'yolo_mid_block.2.bn.weight', 'yolo_mid_block.2.bn.bias', 'yolo_mid_block.3.conv1.weight', 'yolo_mid_block.3.conv1.bias', 'yolo_mid_block.3.conv2.weight', 'yolo_mid_block.3.conv2.bias', 'yolo_mid_block.3.bn.weight', 'yolo_mid_block.3.bn.bias', 'yolo_mid_block.4.conv1.weight', 'yolo_mid_block.4.conv1.bias', 'yolo_mid_block.4.conv2.weight', 'yolo_mid_block.4.conv2.bias', 'yolo_mid_block.4.bn.weight', 'yolo_mid_block.4.bn.bias', 'yolo_mid_block.5.conv1.weight', 'yolo_mid_block.5.conv1.bias', 'yolo_mid_block.5.conv2.weight', 'yolo_mid_block.5.conv2.bias', 'yolo_mid_block.5.bn.weight', 'yolo_mid_block.5.bn.bias', 'yolo_mid_block.6.weight', 'yolo_mid_block.6.bias', 'yolo_end_block.0.weight', 'yolo_end_block.0.bias', 'yolo_end_block.1.weight', 'yolo_end_block.1.bias', 'yolo_end_block.2.conv1.weight', 'yolo_end_block.2.conv1.bias', 'yolo_end_block.2.conv2.weight', 'yolo_end_block.2.conv2.bias', 'yolo_end_block.2.bn.weight', 'yolo_end_block.2.bn.bias', 'yolo_end_block.3.conv1.weight', 'yolo_end_block.3.conv1.bias', 'yolo_end_block.3.conv2.weight', 'yolo_end_block.3.conv2.bias', 'yolo_end_block.3.bn.weight', 'yolo_end_block.3.bn.bias', 'yolo_end_block.4.conv1.weight', 'yolo_end_block.4.conv1.bias', 'yolo_end_block.4.conv2.weight', 'yolo_end_block.4.conv2.bias', 'yolo_end_block.4.bn.weight', 'yolo_end_block.4.bn.bias', 'yolo_end_block.5.conv1.weight', 'yolo_end_block.5.conv1.bias', 'yolo_end_block.5.conv2.weight', 'yolo_end_block.5.conv2.bias', 'yolo_end_block.5.bn.weight', 'yolo_end_block.5.bn.bias', 'yolo_end_block.6.weight', 'yolo_end_block.6.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQJOeF9RDVnW",
        "outputId": "cae4ffbf-5f2a-45d4-e51c-189957552847"
      },
      "source": [
        "from midas.midas_net import MidasNet\n",
        "\n",
        "midas_model = MidasNet(\"model-f46da743.pt\", non_negative=True)\n",
        "midas_model.eval()\n",
        "midas_model.to(device)\n",
        "print(\"Model Loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights:  model-f46da743.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYofDP-GH37i"
      },
      "source": [
        "for k, v in dict(model.named_parameters()).items():\n",
        "    if 'pretrained' in k:\n",
        "      v.requires_grad = False\n",
        "    # elif 'yolo' in k:\n",
        "    #   v.requires_grad = False\n",
        "    elif 'scratch' in k:\n",
        "      v.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGWir797UoA"
      },
      "source": [
        "import argparse\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import *\n",
        "from datasets import *\n",
        "from utils import *\n",
        "\n",
        "def test(data,\n",
        "         weights=None,\n",
        "         batch_size=16,\n",
        "         img_size=416,\n",
        "         conf_thres=0.001,\n",
        "         iou_thres=0.6,  # for nms\n",
        "         save_json=False,\n",
        "         single_cls=False,\n",
        "         augment=False,\n",
        "         model=None,\n",
        "         dataloader=None):\n",
        "\n",
        "    device = next(model.parameters()).device  # get model device\n",
        "    verbose = False\n",
        "\n",
        "    # Configure run\n",
        "    nc = 1 if single_cls else int(data['classes'])  # number of classes\n",
        "    path = data['valid']  # path to test images\n",
        "    names = load_classes(data['names'])  # class names\n",
        "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
        "    iouv = iouv[0].view(1)  # comment for mAP@0.5:0.95\n",
        "    niou = iouv.numel()\n",
        "\n",
        "    seen = 0\n",
        "    model.eval()\n",
        "\n",
        "    s = ('%20s' + '%10s' * 6) % ('Class', 'Images', 'Targets', 'P', 'R', 'mAP@0.5', 'F1')\n",
        "    p, r, f1, mp, mr, map, mf1, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
        "    loss = torch.zeros(3, device=device)\n",
        "    jdict, stats, ap, ap_class = [], [], [], []\n",
        "    for batch_i, (imgs, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
        "        imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        nb, _, height, width = imgs.shape  # batch size, channels, height, width\n",
        "        whwh = torch.Tensor([width, height, width, height]).to(device)\n",
        "\n",
        "        # Plot images with bounding boxes\n",
        "        f = 'test_batch%g.png' % batch_i  # filename\n",
        "        if batch_i < 1 and not os.path.exists(f):\n",
        "            plot_images(imgs=imgs, targets=targets, paths=paths, fname=f)\n",
        "\n",
        "        # Disable gradients\n",
        "        with torch.no_grad():\n",
        "            # Run model\n",
        "            t = time_synchronized()\n",
        "            _, inf_out, train_out = model(imgs)  # inference and training outputs\n",
        "            t0 += time_synchronized() - t\n",
        "\n",
        "            # Compute loss\n",
        "            if hasattr(model, 'hyp'):  # if model has loss hyperparameters\n",
        "                loss += compute_loss(train_out, targets, model)[1][:3]  # GIoU, obj, cls\n",
        "\n",
        "            # Run NMS\n",
        "            t = time_synchronized()\n",
        "            output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)  # nms\n",
        "            t1 += time_synchronized() - t\n",
        "\n",
        "        # Statistics per image\n",
        "        for si, pred in enumerate(output):\n",
        "            labels = targets[targets[:, 0] == si, 1:]\n",
        "            nl = len(labels)\n",
        "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
        "            seen += 1\n",
        "\n",
        "            if pred is None:\n",
        "                if nl:\n",
        "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
        "                continue\n",
        "\n",
        "            # Append to text file\n",
        "            # with open('test.txt', 'a') as file:\n",
        "            #    [file.write('%11.5g' * 7 % tuple(x) + '\\n') for x in pred]\n",
        "\n",
        "            # Clip boxes to image bounds\n",
        "            clip_coords(pred, (height, width))\n",
        "\n",
        "            # Assign all predictions as incorrect\n",
        "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
        "            if nl:\n",
        "                detected = []  # target indices\n",
        "                tcls_tensor = labels[:, 0]\n",
        "\n",
        "                # target boxes\n",
        "                tbox = xywh2xyxy(labels[:, 1:5]) * whwh\n",
        "\n",
        "                # Per target class\n",
        "                for cls in torch.unique(tcls_tensor):\n",
        "                    ti = (cls == tcls_tensor).nonzero().view(-1)  # prediction indices\n",
        "                    pi = (cls == pred[:, 5]).nonzero().view(-1)  # target indices\n",
        "\n",
        "                    # Search for detections\n",
        "                    if pi.shape[0]:\n",
        "                        # Prediction to target ious\n",
        "                        ious, i = box_iou(pred[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
        "\n",
        "                        # Append detections\n",
        "                        for j in (ious > iouv[0]).nonzero():\n",
        "                            d = ti[i[j]]  # detected target\n",
        "                            if d not in detected:\n",
        "                                detected.append(d)\n",
        "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
        "                                if len(detected) == nl:  # all targets already located in image\n",
        "                                    break\n",
        "                                    \n",
        "            # Append statistics (correct, conf, pcls, tcls)\n",
        "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
        "\n",
        "    # Compute statistics\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
        "    if len(stats):\n",
        "        p, r, ap, f1, ap_class = ap_per_class(*stats)\n",
        "        if niou > 1:\n",
        "            p, r, ap, f1 = p[:, 0], r[:, 0], ap.mean(1), ap[:, 0]  # [P, R, AP@0.5:0.95, AP@0.5]\n",
        "        mp, mr, map, mf1 = p.mean(), r.mean(), ap.mean(), f1.mean()\n",
        "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
        "    else:\n",
        "        nt = torch.zeros(1)\n",
        "\n",
        "    # Print results\n",
        "    pf = '%20s' + '%10.3g' * 6  # print format\n",
        "    print(pf % ('all', seen, nt.sum(), mp, mr, map, mf1))\n",
        "\n",
        "    # Print results per class\n",
        "    if verbose and nc > 1 and len(stats):\n",
        "        for i, c in enumerate(ap_class):\n",
        "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap[i], f1[i]))\n",
        "\n",
        "    # Print speeds\n",
        "    if verbose or save_json:\n",
        "        t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (img_size, img_size, batch_size)  # tuple\n",
        "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
        "\n",
        "\n",
        "    maps = np.zeros(nc) + map\n",
        "    for i, c in enumerate(ap_class):\n",
        "        maps[c] = ap[i]\n",
        "    return (mp, mr, map, mf1, *(loss.cpu() / len(dataloader)).tolist()), maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgscBj0-IQX",
        "outputId": "9e2b51ea-55b0-43c3-ccb7-610785b8744c"
      },
      "source": [
        "results, maps = test(data,\n",
        "                          batch_size=1,\n",
        "                          img_size=img_size,\n",
        "                          model=ema.ema,\n",
        "                          save_json=False,\n",
        "                          single_cls=False,\n",
        "                          iou_thres=0.6,\n",
        "                          dataloader=testloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/317 [00:00<?, ?it/s]/content/TheSchoolOfAI-EVA5-Assignments/Assignment 15/divyam/utils.py:114: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:21<00:00, 15.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000103    0.0777  1.31e-05  0.000205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX2rrAl8EgJ7",
        "outputId": "e874dc9d-8693-4568-d924-e425e87ccaa1"
      },
      "source": [
        "maps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.49390156e-05, 3.85382329e-06, 5.17771443e-06, 1.82631328e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkJz1J_y9Crs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be9c7c8a-4ec6-46e1-971a-7798b3112337"
      },
      "source": [
        "optimizer=optim.SGD(model.parameters(), lr=1e-3, momentum=0.6, weight_decay=hyp['weight_decay'])\n",
        "\n",
        "nc=4\n",
        "# Start training\n",
        "nb = len(dataloader)  # number of batches\n",
        "maps = np.zeros(nc)  # mAP per class\n",
        "nw=4\n",
        "epochs=100\n",
        "start_epoch=0\n",
        "\n",
        "\n",
        "lf = lambda x: (((1 + math.cos(\n",
        "        x * math.pi / epochs)) / 2) ** 1.0) * 0.95 + 0.05\n",
        "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf, last_epoch=start_epoch - 1)\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n",
        "t0 = time.time()\n",
        "# print('Image sizes %g - %g train, %g test' % (imgsz_min, imgsz_max, imgsz_test))\n",
        "print('Using %g dataloader workers' % nw)\n",
        "print('Starting training for %g epochs...' % epochs)\n",
        "for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
        "    model.train()\n",
        "\n",
        "    mloss = torch.zeros(4).to(device)  # mean losses\n",
        "    avg_midas_loss = 0\n",
        "    # print('\\n-----------------Train---------------\\n')\n",
        "    print(('\\n' + '%10s' * 9) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', ' midas_loss', 'img_size'))\n",
        "    pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n",
        "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
        "        ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "        imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # midas_target = midas_model.forward(imgs)\n",
        "        # Run model\n",
        "        midas_pred, pred = model(imgs)\n",
        "        # mse_loss = nn.MSELoss()\n",
        "        # midas_loss = mse_loss(midas_pred, midas_target)/1e5\n",
        "        # Compute loss\n",
        "        loss, loss_items = compute_loss(pred, targets, model)\n",
        "        if not torch.isfinite(loss):\n",
        "          print('WARNING: non-finite loss, ending training ', loss_items)\n",
        "\n",
        "        # Scale loss by nominal batch_size of 64\n",
        "        loss *= batch_size / 64\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        # midas_loss.backward()\n",
        "        # Optimize accumulated gradient\n",
        "        # if ni % accumulate == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        ema.update(model)\n",
        "\n",
        "        # Print batch results\n",
        "        mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "        # avg_midas_loss = (avg_midas_loss * i + midas_loss) / (i + 1)  # update mean losses\n",
        "        mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "        s = ('%10s' * 2 + '%10.3g' * 7) % ('%g/%g' % (epoch, epochs - 1), mem, *mloss, len(targets), avg_midas_loss, img_size)\n",
        "\n",
        "        pbar.set_description(s)\n",
        "\n",
        "\n",
        "        # end batch ------------------------------------------------------------------------------------------------\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "    ema.update_attr(model)\n",
        "    results, maps = test(data,\n",
        "                          batch_size=1,\n",
        "                          img_size=img_size,\n",
        "                          model=ema.ema,\n",
        "                          save_json=False,\n",
        "                          single_cls=False,\n",
        "                          iou_thres=0.6,\n",
        "                          dataloader=testloader)\n",
        "\n",
        "    # mloss = torch.zeros(4).to(device)  # mean losses\n",
        "    # print('\\n-----------------Test---------------\\n')\n",
        "    # print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n",
        "    # pbar = tqdm(enumerate(testloader), total=len(testloader))  # progress bar\n",
        "    # for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
        "    #     ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "    #     imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n",
        "    #     targets = targets.to(device)\n",
        "       \n",
        "    #     # Run model\n",
        "    #     model.eval()\n",
        "    #     _, _, pred = model(imgs)\n",
        "    #     # Compute loss\n",
        "    #     loss, loss_items = compute_loss(pred, targets, model)\n",
        "    #     if not torch.isfinite(loss):\n",
        "    #       print('WARNING: non-finite loss, ending training ', loss_items)\n",
        "\n",
        "    #     # Scale loss by nominal batch_size of 64\n",
        "    #     loss *= batch_size / 64\n",
        "\n",
        "    #     # Optimize accumulated gradient\n",
        "    #     # if ni % accumulate == 0:\n",
        "\n",
        "    #     # Print batch results\n",
        "    #     mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "    #     mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "    #     s = ('%10s' * 2 + '%10.3g' * 6) % ('%g/%g' % (epoch, epochs - 1), mem, *mloss, len(targets), img_size)\n",
        "    #     pbar.set_description(s)\n",
        "\n",
        "    # end epoch ----------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 4 dataloader workers\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3029 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/99     1.97G       5.3      3.25        33      41.5         1         0       512: 100%|██████████| 3029/3029 [11:56<00:00,  4.23it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1:   0%|          | 0/317 [00:00<?, ?it/s]/content/TheSchoolOfAI-EVA5-Assignments/Assignment 15/divyam/utils.py:114: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  1.77e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      1/99     2.21G      4.56       3.4      25.9      33.8         5         0       512: 100%|██████████| 3029/3029 [11:54<00:00,  4.24it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  4.06e-05  0.000512  2.87e-05  7.52e-05\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      2/99      2.4G      4.31       3.7      22.6      30.6         7         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  3.51e-05  0.000512  3.66e-05  6.57e-05\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      3/99      2.4G       4.2      3.77      21.3      29.3        12         0       512: 100%|██████████| 3029/3029 [11:47<00:00,  4.28it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.84e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      4/99      2.4G      4.11      3.76      19.5      27.4         2         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.48e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      5/99      2.4G      4.03      3.78      19.1      26.9         5         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.87e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      6/99      2.4G      3.97      3.83        18      25.8         2         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.57e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      7/99      2.4G      3.92      3.88      17.7      25.5         1         0       512: 100%|██████████| 3029/3029 [11:48<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  4.32e-05  0.000512  4.63e-05  7.96e-05\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      8/99      2.4G      3.88      3.84      17.7      25.4        14         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.52e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "      9/99      2.4G      3.87      3.87      16.8      24.6        12         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.75e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     10/99      2.4G      3.83      3.88      17.1      24.8         3         0       512: 100%|██████████| 3029/3029 [11:46<00:00,  4.29it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  4.85e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     11/99      2.4G       3.8      3.84      16.6      24.2         6         0       512: 100%|██████████| 3029/3029 [11:47<00:00,  4.28it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  5.89e-05  0.000512  5.03e-05  0.000106\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     12/99      2.4G      3.79      3.87        16      23.6         9         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000232   0.00167  4.59e-05  0.000406\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     13/99      2.4G      3.75      3.91      16.2      23.9         3         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000294   0.00218  5.29e-05  0.000517\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     14/99      2.4G      3.77      3.81      15.9      23.4        17         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000364    0.0027  5.71e-05   0.00064\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     15/99      2.4G      3.75      3.85        15      22.6         5         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000479   0.00372  6.76e-05  0.000847\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     16/99      2.4G      3.74      3.86      15.8      23.4         4         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000706   0.00539  0.000489   0.00124\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     17/99      2.4G      3.73      3.81      15.3      22.9        15         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000715   0.00539  0.000496   0.00126\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     18/99      2.4G      3.66      3.79      15.3      22.7         1         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000588   0.00437  0.000479   0.00104\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     19/99      2.4G      3.66       3.8      15.2      22.6         9         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.24it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000603    0.0045  0.000271   0.00106\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     20/99      2.4G      3.66      3.79      14.8      22.2         5         0       512: 100%|██████████| 3029/3029 [11:55<00:00,  4.23it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000544   0.00399  0.000238  0.000957\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     21/99      2.4G      3.64      3.78      14.5      21.9        17         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00053   0.00385  0.000306  0.000931\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     22/99      2.4G      3.64      3.81      14.5        22         1         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000496   0.00334  0.000239  0.000864\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     23/99      2.4G      3.62      3.82        14      21.5         3         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000608   0.00385  0.000239   0.00105\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     24/99      2.4G       3.6      3.75      14.6        22        17         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000565   0.00296  0.000216  0.000947\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     25/99      2.4G      3.59      3.82      14.6        22         5         0       512: 100%|██████████| 3029/3029 [11:56<00:00,  4.23it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000375    0.0018  0.000176  0.000618\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     26/99      2.4G      3.57      3.78      14.3      21.6         4         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000466   0.00232  0.000164  0.000772\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     27/99      2.4G      3.64      3.78      14.1      21.5         4         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000492   0.00232   0.00017  0.000805\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     28/99      2.4G      3.59      3.83      14.1      21.5         9         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000514   0.00232  0.000169  0.000833\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     29/99      2.4G      3.54      3.81      13.4      20.7         3         0       512: 100%|██████████| 3029/3029 [11:53<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000453    0.0018  0.000168  0.000719\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     30/99      2.4G      3.55      3.76      13.9      21.2         5         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000497    0.0018  0.000188  0.000775\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     31/99      2.4G      3.52      3.76      13.4      20.7         5         0       512: 100%|██████████| 3029/3029 [11:48<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000706   0.00245  0.000164   0.00109\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     32/99      2.4G      3.54      3.85      13.5      20.8         3         0       512: 100%|██████████| 3029/3029 [11:52<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000766   0.00245  0.000153   0.00116\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     33/99      2.4G      3.54      3.82      13.2      20.6         1         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000411   0.00116  4.98e-05  0.000603\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     34/99      2.4G      3.53      3.79      13.3      20.6        15         0       512: 100%|██████████| 3029/3029 [11:54<00:00,  4.24it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000144  0.000512   4.4e-05  0.000225\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     35/99      2.4G      3.53      3.72      13.3      20.5         7         0       512: 100%|██████████| 3029/3029 [11:54<00:00,  4.24it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.96e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     36/99      2.4G      3.51      3.76      13.1      20.4         3         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000517  0.000646  6.08e-05  0.000574\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     37/99      2.4G      3.52      3.77      13.5      20.8         3         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000715   0.00116  6.25e-05  0.000846\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     38/99      2.4G      3.49      3.78      12.9      20.2         6         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000799   0.00116  6.24e-05  0.000896\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     39/99      2.4G       3.5      3.75      12.9      20.2         5         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000852   0.00116  7.78e-05  0.000915\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     40/99      2.4G       3.5      3.78      13.2      20.5         4         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000173  0.000512  3.72e-05  0.000258\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     41/99      2.4G      3.51      3.79        13      20.3         3         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:18<00:00, 16.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000168  0.000512  4.12e-05  0.000253\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     42/99      2.4G      3.49      3.74      12.9      20.1         6         0       512: 100%|██████████| 3029/3029 [11:47<00:00,  4.28it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:18<00:00, 16.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000719  0.000646  0.000214  0.000681\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     43/99      2.4G      3.43      3.77      12.4      19.6         6         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000768  0.000646  0.000216  0.000702\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     44/99      2.4G      3.45      3.74      12.7      19.9        12         0       512: 100%|██████████| 3029/3029 [11:52<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00164   0.00129  0.000287   0.00145\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     45/99      2.4G      3.47      3.73      12.3      19.5         7         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.25it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000967  0.000646  0.000287  0.000774\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     46/99      2.4G      3.41      3.69      12.8      19.9         8         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:18<00:00, 16.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00109  0.000646  0.000287  0.000811\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     47/99      2.4G      3.47      3.74      12.6      19.9        14         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00114  0.000646  0.000283  0.000826\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     48/99      2.4G      3.45      3.75      11.8        19         4         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03    0.0012  0.000646  0.000447  0.000839\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     49/99      2.4G      3.43       3.7      12.2      19.3         6         0       512: 100%|██████████| 3029/3029 [11:54<00:00,  4.24it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00128  0.000646  0.000449  0.000859\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     50/99      2.4G      3.46      3.78      12.2      19.5        10         0       512: 100%|██████████| 3029/3029 [11:51<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00122  0.000646  0.000347  0.000844\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     51/99      2.4G      3.44      3.78      12.6      19.8         2         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:18<00:00, 16.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03   0.00114  0.000646   0.00066  0.000824\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     52/99      2.4G      3.43      3.73      12.2      19.3         6         0       512: 100%|██████████| 3029/3029 [11:49<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.36e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     53/99      2.4G      3.44      3.73      12.5      19.6         2         0       512: 100%|██████████| 3029/3029 [11:47<00:00,  4.28it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.15e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     54/99      2.4G      3.39      3.67      11.8      18.9         6         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.26it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.18e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     55/99      2.4G      3.45      3.77      12.3      19.5         2         0       512: 100%|██████████| 3029/3029 [11:50<00:00,  4.27it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:18<00:00, 16.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03         0         0  3.08e-05         0\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     56/99      2.4G      3.42      3.72      11.8        19        11         0       512: 100%|██████████| 3029/3029 [11:48<00:00,  4.28it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 317/317 [00:19<00:00, 16.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 all       317  1.53e+03  0.000897  0.000646  0.000447  0.000751\n",
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets midas_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     57/99      2.4G      3.48      3.84      11.3      18.7         3         0       512:  18%|█▊        | 546/3029 [02:09<09:54,  4.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-76e206ad2950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Print batch results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b943c07869b3>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mmsd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mmsd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mesd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mesd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mstate_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mstate_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mstate_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mstate_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mstate_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mdestination\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_to_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_save_to_state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m                 \u001b[0mdestination\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_vars\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_persistent_buffers_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqt0qKGHVbcQ",
        "outputId": "75d294e5-ba1d-4c8c-db78-c3438ac47c0b"
      },
      "source": [
        "paths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['YoloV3_Dataset/images/ImageYolo (7).jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKSoYyPoLCBc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}